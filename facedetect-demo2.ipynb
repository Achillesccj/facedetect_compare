{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,zipfile\n",
    "\n",
    "files=zipfile.ZipFile('models.zip','r')\n",
    "files.extractall('/home/ma-user/work')\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting dlib\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/a4/7b/2f7f29f460629a8143b2deea1911e2fb1d9d88d29bf645ba321461588e88/dlib-19.21.0.tar.gz (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 57.0 MB/s eta 0:00:01                        | 747 kB 57.0 MB/s eta 0:00:01  | 2.8 MB 57.0 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlib: filename=dlib-19.21.0-cp36-cp36m-linux_x86_64.whl size=3994852 sha256=8f024335a9ff1efe8c7bfb3bf5cf218430c80d32c6ed01e31af3c6acb58d0703\n",
      "  Stored in directory: /home/ma-user/.cache/pip/wheels/13/3e/12/94e41b59715651d0adbf169499dc3fd294a93b25ec360592cb\n",
      "Successfully built dlib\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.21.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d6/bb/8a3d0e7e5545fa2c4ad28366104ecb4721166005e511c5bc7655fb376253/opencv_contrib_python-4.4.0.42-cp36-cp36m-manylinux2014_x86_64.whl (55.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 55.6 MB 224 kB/s eta 0:00:012K     |▍                               | 768 kB 39.8 MB/s eta 0:00:02 |█████▊                          | 9.9 MB 483 kB/s eta 0:01:35kB/s eta 0:01:15/s eta 0:00:56  | 30.3 MB 14.9 MB/s eta 0:00:02MB/s eta 0:00:02MB/s eta 0:00:10███████████████▌          | 37.4 MB 2.2 MB/s eta 0:00:09█████████████▍        | 40.7 MB 2.2 MB/s eta 0:00:070:22��███▉    | 48.4 MB 471 kB/s eta 0:00:16��█████████████████████████▋  | 51.5 MB 471 kB/s eta 0:00:09�██▉| 55.3 MB 478 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages (from opencv-contrib-python) (1.18.4)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.4.0.42\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-contrib-python -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装完后检查OpenCV的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "import dlib\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFaceDlibMMOD(detector, frame, inHeight=300, inWidth=0):\n",
    "\n",
    "    frameDlibMMOD = frame.copy()\n",
    "    #提取图片尺寸\n",
    "    frameHeight = frameDlibMMOD.shape[0]\n",
    "    frameWidth = frameDlibMMOD.shape[1]\n",
    "    if not inWidth:\n",
    "        inWidth = int((frameWidth / frameHeight)*inHeight)\n",
    "\n",
    "    #确定图片的缩放比例\n",
    "    scaleHeight = frameHeight / inHeight\n",
    "    scaleWidth = frameWidth / inWidth\n",
    "\n",
    "    #对图片进行缩放\n",
    "    frameDlibMMODSmall = cv2.resize(frameDlibMMOD, (inWidth, inHeight))\n",
    "\n",
    "    frameDlibMMODSmall = cv2.cvtColor(frameDlibMMODSmall, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #进行人脸识别\n",
    "    faceRects = detector(frameDlibMMODSmall, 0)\n",
    "\n",
    "    #print(frameWidth, frameHeight, inWidth, inHeight)\n",
    "    bboxes = []\n",
    "    for faceRect in faceRects:\n",
    "        #提取人脸的边界坐标\n",
    "        cvRect = [int(faceRect.rect.left()*scaleWidth), int(faceRect.rect.top()*scaleHeight),\n",
    "                  int(faceRect.rect.right()*scaleWidth), int(faceRect.rect.bottom()*scaleHeight) ]\n",
    "        bboxes.append(cvRect)\n",
    "        #将识别结果绘制在图片上\n",
    "        cv2.rectangle(frameDlibMMOD, (cvRect[0], cvRect[1]), (cvRect[2], cvRect[3]), (0, 255, 0), int(round(frameHeight/150)), 4)\n",
    "    return frameDlibMMOD, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFaceDlibHog(detector, frame, inHeight=300, inWidth=0):\n",
    "\n",
    "    frameDlibHog = frame.copy()\n",
    "    frameHeight = frameDlibHog.shape[0]\n",
    "    frameWidth = frameDlibHog.shape[1]\n",
    "    if not inWidth:\n",
    "        inWidth = int((frameWidth / frameHeight)*inHeight)\n",
    "\n",
    "    scaleHeight = frameHeight / inHeight\n",
    "    scaleWidth = frameWidth / inWidth\n",
    "    # scaleHeight=1\n",
    "    # scaleWidth=1\n",
    "    \n",
    "\n",
    "    frameDlibHogSmall = cv2.resize(frameDlibHog, (inWidth, inHeight))\n",
    "\n",
    "    frameDlibHogSmall = cv2.cvtColor(frameDlibHogSmall, cv2.COLOR_BGR2RGB)\n",
    "    # frameDlibHogSmall = cv2.cvtColor(frameDlibHog, cv2.COLOR_BGR2RGB)\n",
    "    faceRects = detector(frameDlibHogSmall, 0)\n",
    "    #print(frameWidth, frameHeight, inWidth, inHeight)\n",
    "    bboxes = []\n",
    "    for faceRect in faceRects:\n",
    "\n",
    "        cvRect = [int(faceRect.left()*scaleWidth), int(faceRect.top()*scaleHeight),\n",
    "                  int(faceRect.right()*scaleWidth), int(faceRect.bottom()*scaleHeight) ]\n",
    "        bboxes.append(cvRect)\n",
    "        cv2.rectangle(frameDlibHog, (cvRect[0], cvRect[1]), (cvRect[2], cvRect[3]), (0, 255, 0), int(round(frameHeight/150)), 4)\n",
    "    return frameDlibHog, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFaceOpenCVDnn(net, frame):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    #去掉改尺寸的部分\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "    # blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0,frameOpencvDnn.shape, [104, 117, 123], False, False)\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFaceOpenCVHaar(faceCascade, frame, inHeight=300, inWidth=0):\n",
    "    frameOpenCVHaar = frame.copy()\n",
    "    frameHeight = frameOpenCVHaar.shape[0]\n",
    "    frameWidth = frameOpenCVHaar.shape[1]\n",
    "    if not inWidth:\n",
    "        inWidth = int((frameWidth / frameHeight) * inHeight)\n",
    "\n",
    "    scaleHeight = frameHeight / inHeight\n",
    "    scaleWidth = frameWidth / inWidth\n",
    "    # scaleHeight=1\n",
    "    # scaleWidth=1\n",
    "\n",
    "    frameOpenCVHaarSmall = cv2.resize(frameOpenCVHaar, (inWidth, inHeight))\n",
    "    frameGray = cv2.cvtColor(frameOpenCVHaarSmall, cv2.COLOR_BGR2GRAY)\n",
    "    # frameGray = cv2.cvtColor(frameOpenCVHaar, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(frameGray)\n",
    "    bboxes = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        x1 = x\n",
    "        y1 = y\n",
    "        x2 = x + w\n",
    "        y2 = y + h\n",
    "        cvRect = [int(x1 * scaleWidth), int(y1 * scaleHeight),\n",
    "                  int(x2 * scaleWidth), int(y2 * scaleHeight)]\n",
    "        bboxes.append(cvRect)\n",
    "        cv2.rectangle(frameOpenCVHaar, (cvRect[0], cvRect[1]), (cvRect[2], cvRect[3]), (0, 255, 0),\n",
    "                      int(round(frameHeight / 150)), 4)\n",
    "    return frameOpenCVHaar, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facedetect_compare(image_name):\n",
    "    \n",
    "    frame=cv2.imread(image_name)\n",
    "    frame_count = 0\n",
    "    tt_opencvHaar = 0\n",
    "    tt_opencvDnn = 0\n",
    "    tt_dlibHog = 0\n",
    "    tt_dlibMmod = 0   \n",
    "    \n",
    "    t = time.time()\n",
    "    outOpencvHaar, bboxes = detectFaceOpenCVHaar(faceCascade, frame)\n",
    "    tt_opencvHaar += time.time() - t\n",
    "    fpsOpencvHaar = frame_count / tt_opencvHaar\n",
    "\n",
    "    label = \"OpenCV Haar ; Time : {:.2f}\".format(tt_opencvHaar)\n",
    "    cv2.putText(outOpencvHaar, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "    t = time.time()\n",
    "    outOpencvDnn, bboxes = detectFaceOpenCVDnn(net,frame)\n",
    "    tt_opencvDnn += time.time() - t\n",
    "    fpsOpencvDnn = frame_count / tt_opencvDnn\n",
    "    label = \"OpenCV DNN ; Time : {:.2f}\".format(tt_opencvDnn)\n",
    "    cv2.putText(outOpencvDnn, label, (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "    t = time.time()\n",
    "    outDlibHog, bboxes = detectFaceDlibHog(hogFaceDetector,frame)\n",
    "    tt_dlibHog += time.time() - t\n",
    "    fpsDlibHog = frame_count / tt_dlibHog\n",
    "\n",
    "    label = \"DLIB HoG ; ; Time : {:.2f}\".format(tt_dlibHog)\n",
    "    cv2.putText(outDlibHog, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "    t = time.time()\n",
    "    outDlibMMOD, bboxes = detectFaceDlibMMOD(dnnFaceDetector,frame)\n",
    "    tt_dlibMmod += time.time() - t\n",
    "    fpsDlibMmod = frame_count / tt_dlibMmod\n",
    "\n",
    "    label = \"DLIB MMOD ; Time : {:.2f}\".format(tt_dlibMmod)\n",
    "    cv2.putText(outDlibMMOD, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "    top = np.hstack([outOpencvHaar, outOpencvDnn])\n",
    "    bottom = np.hstack([outDlibHog, outDlibMMOD])\n",
    "    combined = np.vstack([top, bottom])\n",
    "    cv2.imwrite('Compare-'+image_name, combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dlib MMOD视频处理\n",
    "def videoface_DlibMMOD(vedio_name):\n",
    "    cap = cv2.VideoCapture(vedio_name)\n",
    "    hasFrame, frame = cap.read()       \n",
    "    vid_writer = cv2.VideoWriter('Dlib MMOD-output-{}.avi'.format(str(vedio_name).split(\".\")[0]),cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1],frame.shape[0]))\n",
    "    frame_count = 0\n",
    "    tt_dlibMmod = 0 \n",
    "    while cap.isOpened():   \n",
    "        hasFrame, frame = cap.read()\n",
    "        if hasFrame!= True:\n",
    "             break        \n",
    "        t = time.time()\n",
    "        outDlibMMOD, bboxes = detectFaceDlibMMOD(dnnFaceDetector,frame)\n",
    "        tt_dlibMmod += time.time() - t\n",
    "        fpsDlibMmod = frame_count / tt_dlibMmod\n",
    "\n",
    "        label = \"DLIB MMOD ; Time : {:.2f}\".format(tt_dlibMmod)\n",
    "        cv2.putText(outDlibMMOD, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        \n",
    "        if frame_count == 1:\n",
    "            \n",
    "            tt_dlibMmod = 0\n",
    "        vid_writer.write(outDlibMMOD)\n",
    "        k = cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dlib hog视频处理\n",
    "def videoface_DlibHog(vedio_name):\n",
    "    cap = cv2.VideoCapture(vedio_name)\n",
    "    hasFrame, frame = cap.read()\n",
    "       \n",
    "    vid_writer = cv2.VideoWriter('DlibHog-output-{}.avi'.format(str(vedio_name).split(\".\")[0]),cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1],frame.shape[0]))\n",
    "    frame_count = 0\n",
    "    tt_dlibHog = 0\n",
    "    \n",
    "    while cap.isOpened():         \n",
    "    \n",
    "        hasFrame, frame = cap.read()\n",
    "        if hasFrame!= True:\n",
    "             break    \n",
    "        t = time.time()\n",
    "        outDlibHog, bboxes = detectFaceDlibHog(hogFaceDetector,frame)\n",
    "        tt_dlibHog += time.time() - t\n",
    "        fpsDlibHog = frame_count / tt_dlibHog\n",
    "\n",
    "        label = \"DLIB HoG ; ; Time : {:.2f}\".format(tt_dlibHog)\n",
    "        cv2.putText(outDlibHog, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        \n",
    "        if frame_count == 1:\n",
    "           \n",
    "            tt_dlibHog = 0\n",
    "            \n",
    "        vid_writer.write(outDlibHog)\n",
    "        k = cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV Haar视频处理\n",
    "def videoface_OpenCVHaar(vedio_name):\n",
    "    cap = cv2.VideoCapture(vedio_name)\n",
    "    hasFrame, frame = cap.read()\n",
    "       \n",
    "    vid_writer = cv2.VideoWriter('OpenCVHaar-output-{}.avi'.format(str(vedio_name).split(\".\")[0]),cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1],frame.shape[0]))\n",
    "    frame_count = 0\n",
    "    tt_opencvHaar = 0\n",
    "    \n",
    "    while cap.isOpened():         \n",
    "    \n",
    "        hasFrame, frame = cap.read()\n",
    "        if hasFrame!= True:\n",
    "             break    \n",
    "        t = time.time()\n",
    "        outOpencvHaar, bboxes = detectFaceOpenCVHaar(faceCascade, frame)\n",
    "        tt_opencvHaar += time.time() - t\n",
    "        fpsOpencvHaar = frame_count / tt_opencvHaar\n",
    "\n",
    "        label = \"OpenCV Haar ; Time : {:.2f}\".format(tt_opencvHaar)\n",
    "        cv2.putText(outOpencvHaar, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        \n",
    "        if frame_count == 1:\n",
    "            tt_opencvHaar = 0\n",
    "            \n",
    "        vid_writer.write(outOpencvHaar)\n",
    "        k = cv2.waitKey(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV Dnn视频处理\n",
    "def videoface_OpenCVDnn(vedio_name):\n",
    "    cap = cv2.VideoCapture(vedio_name)\n",
    "    hasFrame, frame = cap.read()\n",
    "       \n",
    "    vid_writer = cv2.VideoWriter('OpenCVDnn-output-{}.avi'.format(str(vedio_name).split(\".\")[0]),cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1],frame.shape[0]))\n",
    "    frame_count = 0\n",
    "    tt_opencvDnn = 0\n",
    "    \n",
    "    while cap.isOpened():         \n",
    "        hasFrame, frame = cap.read()\n",
    "        if hasFrame!= True:\n",
    "             break    \n",
    "        \n",
    "        t = time.time()\n",
    "        outOpencvDnn, bboxes = detectFaceOpenCVDnn(net,frame)\n",
    "        tt_opencvDnn += time.time() - t\n",
    "        fpsOpencvDnn = frame_count / tt_opencvDnn\n",
    "        label = \"OpenCV DNN ; Time : {:.2f}\".format(tt_opencvDnn)\n",
    "        cv2.putText(outOpencvDnn, label, (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        \n",
    "    #cv2.imwrite('Compare-'+image_name, combined)\n",
    "        if frame_count == 1:\n",
    "            \n",
    "            tt_opencvDnn = 0\n",
    "            \n",
    "        vid_writer.write(outOpencvDnn)\n",
    "        k = cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opencv_compare(vedio_name):\n",
    "    cap = cv2.VideoCapture(vedio_name)\n",
    "    hasFrame, frame = cap.read()\n",
    "       \n",
    "    vid_writer = cv2.VideoWriter('opencv-compar-{}.avi'.format(str(vedio_name).split(\".\")[0]),cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1]*2,frame.shape[0]))\n",
    "    frame_count = 0\n",
    "    tt_opencvHaar = 0\n",
    "    tt_opencvDnn = 0\n",
    "    tt_dlibHog = 0\n",
    "    tt_dlibMmod = 0 \n",
    "    while cap.isOpened(): \n",
    "        \n",
    "        hasFrame, frame = cap.read()\n",
    "        if hasFrame!= True:\n",
    "             break    \n",
    "        t = time.time()\n",
    "        outOpencvHaar, bboxes = detectFaceOpenCVHaar(faceCascade, frame)\n",
    "        tt_opencvHaar += time.time() - t\n",
    "        fpsOpencvHaar = frame_count / tt_opencvHaar\n",
    "\n",
    "        label = \"OpenCV Haar ; FPS : {:.2f}\".format(tt_opencvHaar)\n",
    "        cv2.putText(outOpencvHaar, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        t = time.time()\n",
    "        outOpencvDnn, bboxes = detectFaceOpenCVDnn(net,frame)\n",
    "        tt_opencvDnn += time.time() - t\n",
    "        fpsOpencvDnn = frame_count / tt_opencvDnn\n",
    "        label = \"OpenCV DNN ; FPS : {:.2f}\".format(tt_opencvDnn)\n",
    "        cv2.putText(outOpencvDnn, label, (10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "        top = np.hstack([outOpencvHaar, outOpencvDnn])\n",
    "        \n",
    "        \n",
    "    #cv2.imwrite('Compare-'+image_name, combined)\n",
    "        if frame_count == 1:\n",
    "            tt_opencvHaar = 0\n",
    "            tt_opencvDnn = 0\n",
    "            tt_dlibHog = 0\n",
    "            tt_dlibMmod = 0\n",
    "        vid_writer.write(top)\n",
    "    vid_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dlib_compare(vedio_name):\n",
    "    cap = cv2.VideoCapture(vedio_name)\n",
    "    hasFrame, frame = cap.read()\n",
    "       \n",
    "    vid_writer = cv2.VideoWriter('dlib_compare-{}.avi'.format(str(vedio_name).split(\".\")[0]),cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1]*2,frame.shape[0]*2))\n",
    "    frame_count = 0\n",
    "    tt_opencvHaar = 0\n",
    "    tt_opencvDnn = 0\n",
    "    tt_dlibHog = 0\n",
    "    tt_dlibMmod = 0 \n",
    "    while cap.isOpened(): \n",
    "        \n",
    "        hasFrame, frame = cap.read()\n",
    "        if hasFrame!= True:\n",
    "             break    \n",
    "        \n",
    "\n",
    "        t = time.time()\n",
    "        outDlibHog, bboxes = detectFaceDlibHog(hogFaceDetector,frame)\n",
    "        tt_dlibHog += time.time() - t\n",
    "        fpsDlibHog = frame_count / tt_dlibHog\n",
    "\n",
    "        label = \"DLIB HoG ; ; FPS : {:.2f}\".format(tt_dlibHog)\n",
    "        cv2.putText(outDlibHog, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        t = time.time()\n",
    "        outDlibMMOD, bboxes = detectFaceDlibMMOD(dnnFaceDetector,frame)\n",
    "        tt_dlibMmod += time.time() - t\n",
    "        fpsDlibMmod = frame_count / tt_dlibMmod\n",
    "\n",
    "        label = \"DLIB MMOD ; FPS : {:.2f}\".format(tt_dlibMmod)\n",
    "        cv2.putText(outDlibMMOD, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        #top = np.hstack([outOpencvHaar, outOpencvDnn])\n",
    "        bottom = np.hstack([outDlibHog, outDlibMMOD])\n",
    "        #combined = np.vstack([top, bottom])\n",
    "    #cv2.imwrite('Compare-'+image_name, combined)\n",
    "        if frame_count == 1:\n",
    "            tt_opencvHaar = 0\n",
    "            tt_opencvDnn = 0\n",
    "            tt_dlibHog = 0\n",
    "            tt_dlibMmod = 0\n",
    "        vid_writer.write(bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoface_compare(vedio_name):\n",
    "    cap = cv2.VideoCapture(vedio_name)\n",
    "    hasFrame, frame = cap.read()\n",
    "       \n",
    "    vid_writer = cv2.VideoWriter('output-{}.avi'.format(str(vedio_name).split(\".\")[0]),cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1]*2,frame.shape[0]*2))\n",
    "    frame_count = 0\n",
    "    tt_opencvHaar = 0\n",
    "    tt_opencvDnn = 0\n",
    "    tt_dlibHog = 0\n",
    "    tt_dlibMmod = 0 \n",
    "    while cap.isOpened(): \n",
    "        \n",
    "        hasFrame, frame = cap.read()\n",
    "        if hasFrame!= True:\n",
    "             break    \n",
    "        t = time.time()\n",
    "        outOpencvHaar, bboxes = detectFaceOpenCVHaar(faceCascade, frame)\n",
    "        tt_opencvHaar += time.time() - t\n",
    "        fpsOpencvHaar = frame_count / tt_opencvHaar\n",
    "\n",
    "        label = \"OpenCV Haar ; FPS : {:.2f}\".format(tt_opencvHaar)\n",
    "        cv2.putText(outOpencvHaar, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        t = time.time()\n",
    "        outOpencvDnn, bboxes = detectFaceOpenCVDnn(net,frame)\n",
    "        tt_opencvDnn += time.time() - t\n",
    "        fpsOpencvDnn = frame_count / tt_opencvDnn\n",
    "        label = \"OpenCV DNN ; FPS : {:.2f}\".format(tt_opencvDnn)\n",
    "        cv2.putText(outOpencvDnn, label, (10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        t = time.time()\n",
    "        outDlibHog, bboxes = detectFaceDlibHog(hogFaceDetector,frame)\n",
    "        tt_dlibHog += time.time() - t\n",
    "        fpsDlibHog = frame_count / tt_dlibHog\n",
    "\n",
    "        label = \"DLIB HoG ; ; FPS : {:.2f}\".format(tt_dlibHog)\n",
    "        cv2.putText(outDlibHog, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        t = time.time()\n",
    "        outDlibMMOD, bboxes = detectFaceDlibMMOD(dnnFaceDetector,frame)\n",
    "        tt_dlibMmod += time.time() - t\n",
    "        fpsDlibMmod = frame_count / tt_dlibMmod\n",
    "\n",
    "        label = \"DLIB MMOD ; FPS : {:.2f}\".format(tt_dlibMmod)\n",
    "        cv2.putText(outDlibMMOD, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        top = np.hstack([outOpencvHaar, outOpencvDnn])\n",
    "        bottom = np.hstack([outDlibHog, outDlibMMOD])\n",
    "        combined = np.vstack([top, bottom])\n",
    "    #cv2.imwrite('Compare-'+image_name, combined)\n",
    "        if frame_count == 1:\n",
    "            tt_opencvHaar = 0\n",
    "            tt_opencvDnn = 0\n",
    "            tt_dlibHog = 0\n",
    "            tt_dlibMmod = 0\n",
    "        vid_writer.write(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m模型的初始化\n",
    "#OpenCV Haar\n",
    "faceCascade = cv2.CascadeClassifier('./models/haarcascade_frontalface_default.xml')\n",
    "\n",
    "#OpenCV Dnn模型加载\n",
    "modelFile = \"./models/opencv_face_detector_uint8.pb\"\n",
    "configFile = \"./models/opencv_face_detector.pbtxt\"\n",
    "net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "\n",
    "conf_threshold = 0.7\n",
    "\n",
    "# DLIB HoG\n",
    "hogFaceDetector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# DLIB MMOD\n",
    "dnnFaceDetector = dlib.cnn_face_detection_model_v1(\"./models/mmod_human_face_detector.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencv_compare('Dengchao.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlib_compare('Dengchao.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoface_compare('Dengchao.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoface_OpenCVHaar('Dengchao.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoface_DlibHog('Dengchao.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-2.1.0",
   "language": "python",
   "name": "tensorflow-2.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
